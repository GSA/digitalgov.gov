---


date: 2013-03-12 1:11:57 -0400
title: 'API Analytics'
summary: 'Similar to website analytics, API analytics focus on reliably reporting the metrics which are most useful to its stakeholders. There are a many ways of collecting, reporting, and consuming API analytics but all revolve around the industry&ndash;accepted norm that some form of analytics are crucial to any API program. The most basic metrics will track'
authors: [gray-brooks]
categories:
  - API
  - Code
  - Metrics
tags:
  - API
---


{% include image/full-width.html img="https://s3.amazonaws.com/sitesusa/wp-content/uploads/sites/212/2014/08/250-x-86-API-letter-blocks-23575697-Hemera-Technologies-PhotoObjects.net-Thinkstock-87667306.jpg" alt="Children's building blocks letters spelling A P I." %} 

Similar to website analytics, API analytics focus on reliably reporting the metrics which are most useful to its stakeholders. There are a many ways of collecting, reporting, and consuming API analytics but all revolve around the industry–accepted norm that some form of analytics are crucial to any API program. The most basic metrics will track the number of API registrations and the number of API requests, but as important as understanding how much an API is used is understanding how it is used.

A first step in any analytics program is always to begin a list of what metrics are desired and why. Basic metrics begin to tell the story of how popular an API but [further metrics offer much more](http://blog.programmableweb.com/2012/08/02/the-api-measurement-secret-know-what-metrics-matter/). By using more advanced analytics, you can begin to understand which parts of your data are more popular and why.

Depending on how your [API is generated](https://www.WHATEVER/2013/03/12/how-to-make-apis-an-overview/ "How to Make APIs—An Overview"), you may have different options for analytics. The more complex and mature the API, the more advanced the potential integration. At the most basic level, basic queries against server logs will enable a baseline of information. By working with the technical team, you can explore more complex options, many of which [may be free and open source](http://www.apievangelist.com/2011/06/23/api-ecosystem-tracking-with-statsd-and-graphite/). Their integration into the system, just like any other functionality, may require a cost–benefit analysis of the development hours versus the capability delivered. Alternatively, several third party service providers [such as 3Scale, Apigee, Atmosphere, and Mashery](http://apievangelist.com/2012/06/15/roundup-of-20-api-service-providers-in-2012/) provide API management platforms which can be placed on top of your API catalog without any technical integration. These are then able to provide numerous services, including but not limited to robust analytics.

At this stage, it is important to view the entire API process as discrete stages and to focus on analytics specific to each one. This mindset opens the door to [performance optimizations](http://blog.programmableweb.com/2011/07/13/whats-next-for-apis-performance-tuning/) but more fundamentally, equips your team to respond to the needs and wants of your developers. Engaging those who are using your API to debug their usage and otherwise support them will promote greater adoption and help you to understand the role of APIs for your agency in ways that complement the power of analytics. [As one analyst notes](http://www.apievangelist.com/2011/03/31/api-metrics-and-analytics/), &#8220;API owners should be measuring every aspect of their API and its community, and be constantly reassessing their strategy based upon what is going on in real–time.&#8221; The same author later [articulated one straightforward strategy](http://www.apievangelist.com/2012/09/18/simple-api-developer-tracking-framework/) for doing just this. NPR’s API program also [provides a fully fleshed–out model](http://blog.programmableweb.com/2010/09/15/metrics-for-content-apis-an-npr-case-study/) for not just the collecting of API analytics but the thorough and practical use of those metrics. Your team should review the common use cases and potential areas for improvement that best fit your agency and construct a model to iterate as your program matures.